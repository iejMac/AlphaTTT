# Behavioral cloning üîçüôç:
This approach uses a dataset I generated by playing with friends to train a model to play the move it thinks a human would play.

## Results üìä:
#### Positive results ‚úÖ:
1. Location invariance - Model prefers to play in the center but if its opponent starts in other regions of the board (- some edge cases mentioned later) it also manages to play well.
2. Defence - Makes moves that prevent opponent from winning
3. Pretty good - Seems to play the game pretty well. Sometimes allows opponent to make attacking moves if it knows it can shut them down later in the game. It even beat me once.

#### Negative results ‚ùå:
1. Very sensative to out-of-distribution positions - Doesn't seem to generalize to very edge case positions such as the opponent playing at the edge of the board (can be defeated by just placing 5 consecutive moves at the edge).
2. Performs worse as game-length increases - As the number of tokens on the board increases past the amount it is used to seeing it begins to overlook threats or it's own attacks.
3. No REINFORCE - Couldn't get the REINFORCE algorithm to strengthen the policy network, likely due to a lack of noise during self-play.

## Data Augmentation:
The data was augmented in 3 different ways: 
1. Rotations of the board
2. Symmetries about the dominant diagonal of the board
3. Translations of the game cluster - in order to acheive location invariance I took the set of moves, found the positions of the 4 tokens that were closest to the 4 edges respectivey and translated all of the moves by some vector [dx, dy] that would give you the same game but in another location of the board. (This form of augmentation proved to be most effective)

## Files üìÅ:
1. gym.py - Trains the policy network using the REINFORCE algorithm.
2. environment.py - Environment class, used to control the MDP.
3. game_mechanics.py - Functions that help with board manipulation (board creation, making moves, checking if the game is over, etc.)
3. model_new.py - Model class, creates the network, trains it, evaluates it, and predicts actions.
4. GUI.py - Interface for viewing games, playing games PvP (policy data generation), and playing games PvAI (model evaluation)
5. data_functions.py - Functions that manipulate, augment, or load data.
