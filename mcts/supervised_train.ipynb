{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "editorial-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from model import ZeroTTT\n",
    "from database import DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "brilliant-interface",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRemember that last index of first batch games is 17\\n                            second batch games is 37\\n                            third batch games is 61\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparams:\n",
    "epochs = 1\n",
    "lr = 3e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "batch_size=40\n",
    "'''\n",
    "Remember that last index of first batch games is 17\n",
    "                            second batch games is 37\n",
    "                            third batch games is 61\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quick-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading brain...\n"
     ]
    }
   ],
   "source": [
    "database = DataBase()\n",
    "db_path = \"/storage/replay_buffer\"\n",
    "model = ZeroTTT(brain_path=\"trained_model_2\", opt_path=\"trained_opt_state_2\", lr=lr, weight_decay=weight_decay, board_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "integrated-insurance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310455\n"
     ]
    }
   ],
   "source": [
    "print(model.get_parameter_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incredible-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_paths = [os.path.join(db_path, \"states\", name) for name in sorted(os.listdir(\"/storage/replay_buffer/states\"))]\n",
    "policy_paths = [os.path.join(db_path, \"policy_labels\", name) for name in sorted(os.listdir(\"/storage/replay_buffer/policy_labels\"))]\n",
    "value_paths = [os.path.join(db_path, \"value_labels\", name) for name in sorted(os.listdir(\"/storage/replay_buffer/value_labels\"))]\n",
    "\n",
    "names = list(zip(state_paths, policy_paths, value_paths))\n",
    "filtered_names = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    index = int(names[i][0].split(\"_\")[-1][:-4])\n",
    "    if index > 37:\n",
    "        filtered_names.append(names[i])\n",
    "names = filtered_names\n",
    "#test_set = names[-2:]\n",
    "#names = names[:-2]\n",
    "test_set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dental-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss(model):\n",
    "    model.brain.eval()\n",
    "    total_p_loss = 0.0\n",
    "    total_v_loss = 0.0\n",
    "    for s, p, v in test_set:\n",
    "        batch_sts, batch_pls, batch_vls = database.prepare_batches(batch_size=batch_size, from_memory_paths=(s, p, v))\n",
    "        for b_nr in range(len(batch_sts)):\n",
    "            batch_st, batch_pl, batch_vl = batch_sts[b_nr], batch_pls[b_nr], batch_vls[b_nr]\n",
    "            \n",
    "            batch_pl = torch.from_numpy(batch_pl).to(model.device)\n",
    "            batch_vl = torch.from_numpy(batch_vl).float().to(model.device)\n",
    "            prob, val = model.predict(batch_st, interpret_policy=False)\n",
    "            val = val.flatten()\n",
    "\n",
    "            p_loss = model.policy_loss(prob, batch_pl)\n",
    "            v_loss = model.value_loss(val, batch_vl)\n",
    "        \n",
    "            total_p_loss += p_loss.item()\n",
    "            total_v_loss += v_loss.item()\n",
    "    return total_p_loss/(len(batch_sts)*len(test_set)), total_v_loss/(len(batch_sts)*len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unlimited-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 train policy loss: 3.9265664512584344 | train value loss: 0.3960440876316279\n",
      "Test policy loss: 3.938411141882493 | Test value loss: 1.1161868854761123\n",
      "Saving brain...\n",
      "Epoch #1 train policy loss: 3.9012286120829534 | train value loss: 0.2984295805723576\n",
      "Test policy loss: 3.925801999469862 | Test value loss: 1.131634916961193\n",
      "Saving brain...\n",
      "Epoch #2 train policy loss: 3.886272855965025 | train value loss: 0.22651439798464576\n",
      "Test policy loss: 3.920096372455512 | Test value loss: 1.1393196768164635\n",
      "Saving brain...\n",
      "Epoch #3 train policy loss: 3.8777887788195162 | train value loss: 0.1899621801703364\n",
      "Test policy loss: 3.9127682451246475 | Test value loss: 1.1901979405879974\n",
      "Saving brain...\n",
      "Epoch #4 train policy loss: 3.871733981637099 | train value loss: 0.16762834739948315\n",
      "Test policy loss: 3.9119438226555348 | Test value loss: 1.1897726495265961\n",
      "Saving brain...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a15e23c95b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbatch_sts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_vls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_memory_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb_nr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mbatch_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_vl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_vls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_nr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_policy_losses = []\n",
    "train_value_losses = []\n",
    "test_policy_losses = []\n",
    "test_value_losses = []\n",
    "for e in range(epochs):\n",
    "    model.brain.train()\n",
    "    cumulative_policy_epoch_loss = 0.0\n",
    "    cumulative_value_epoch_loss = 0.0\n",
    "    for s_name, p_name, v_name in names:\n",
    "        batch_sts, batch_pls, batch_vls = database.prepare_batches(batch_size=batch_size, from_memory_paths=(s_name, p_name, v_name))\n",
    "        for b_nr in range(len(batch_sts)):\n",
    "            model.optimizer.zero_grad()\n",
    "            batch_st, batch_pl, batch_vl = batch_sts[b_nr], batch_pls[b_nr], batch_vls[b_nr]\n",
    "            \n",
    "            batch_pl = torch.from_numpy(batch_pl).to(model.device)\n",
    "            batch_vl = torch.from_numpy(batch_vl).float().to(model.device)\n",
    "            prob, val = model.predict(batch_st, interpret_policy=False)\n",
    "            val = val.flatten()\n",
    "\n",
    "            p_loss = model.policy_loss(prob, batch_pl)\n",
    "            v_loss = model.value_loss(val, batch_vl)\n",
    "                        \n",
    "            cumulative_policy_epoch_loss += p_loss.item()\n",
    "            cumulative_value_epoch_loss += v_loss.item()\n",
    "\n",
    "            loss = p_loss + v_loss\n",
    "            loss.backward()\n",
    "   \n",
    "            model.optimizer.step()\n",
    "    \n",
    "    # Loss on test set:\n",
    "    cumulative_policy_epoch_loss /= len(names)*len(batch_sts) # div by batch count\n",
    "    cumulative_value_epoch_loss /= len(names)*len(batch_sts)\n",
    "    # test_epoch_policy_loss, test_epoch_value_loss = test_loss(model)\n",
    "    print(f\"Epoch #{e} train policy loss: {cumulative_policy_epoch_loss} | train value loss: {cumulative_value_epoch_loss}\")\n",
    "    # print(f\"Test policy loss: {test_epoch_policy_loss} | Test value loss: {test_epoch_value_loss}\")\n",
    "    train_policy_losses.append(cumulative_policy_epoch_loss)\n",
    "    train_value_losses.append(cumulative_value_epoch_loss)\n",
    "    # test_policy_losses.append(test_epoch_policy_loss)\n",
    "    # test_value_losses.append(test_epoch_value_loss)\n",
    "    # Checkpoint:\n",
    "    model.save_brain(\"trained_model_3\", \"trained_opt_state_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_value_losses)\n",
    "plt.plot(test_value_losses)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_policy_losses)\n",
    "plt.plot(test_policy_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-tribe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
